
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broiler Weight Estimation - Example Inference\n",
    "\n",
    "This notebook demonstrates how to use the broiler weight estimation pipeline for inference on RGB and depth image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from pipeline.pipeline import BroilerWeightPipeline\n",
    "from pipeline.utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Pipeline\n",
    "\n",
    "Load the configuration and initialize the pipeline with trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config('../pipeline/config.yaml')\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"- Model artifacts dir: {config['model']['artifacts_dir']}\")\n",
    "print(f\"- Default model type: {config['inference']['model_type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = BroilerWeightPipeline('../pipeline/config.yaml')\n",
    "\n",
    "# Load trained models\n",
    "try:\n",
    "    pipeline.load_models()\n",
    "    print(\"Models loaded successfully!\")\n",
    "    \n",
    "    # Display model information\n",
    "    model_info = pipeline.get_model_info()\n",
    "    print(\"\\nModel Information:\")\n",
    "    for key, value in model_info.items():\n",
    "        print(f\"- {key}: {value}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not load models: {e}\")\n",
    "    print(\"You may need to train models first using: python pipeline/train.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single Image Inference\n",
    "\n",
    "Demonstrate inference on a single RGB-Depth image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example paths (update these to your actual data)\n",
    "rgb_image_path = \"../data/rgb/rgb_20250725_162941_594732_instance-0.png\"\n",
    "depth_file_path = \"../data/depth/depth_20250725_162941_594732_instance-0.npy\"\n",
    "\n",
    "# Check if example files exist\n",
    "if os.path.exists(rgb_image_path) and os.path.exists(depth_file_path):\n",
    "    try:\n",
    "        # Run inference\n",
    "        predicted_weight = pipeline.predict_from_images(rgb_image_path, depth_file_path)\n",
    "        \n",
    "        print(f\"Input RGB image: {rgb_image_path}\")\n",
    "        print(f\"Input depth file: {depth_file_path}\")\n",
    "        print(f\"Predicted weight: {predicted_weight:.3f} kg\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Inference failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Example data files not found. Update the paths above to your actual data.\")\n",
    "    print(f\"Looking for RGB: {rgb_image_path}\")\n",
    "    print(f\"Looking for Depth: {depth_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Inference\n",
    "\n",
    "Run inference on multiple image pairs from directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example directories (update these to your actual data)\n",
    "rgb_directory = \"../data/rgb\"\n",
    "depth_directory = \"../data/depth\"\n",
    "\n",
    "# Check if directories exist\n",
    "if os.path.exists(rgb_directory) and os.path.exists(depth_directory):\n",
    "    try:\n",
    "        # Run batch inference\n",
    "        results = pipeline.predict_from_directory(rgb_directory, depth_directory)\n",
    "        \n",
    "        print(f\"Processed {len(results)} image pairs\")\n",
    "        print(f\"Mean predicted weight: {results['predicted_weight_kg'].mean():.3f} kg\")\n",
    "        print(f\"Weight range: {results['predicted_weight_kg'].min():.3f} - {results['predicted_weight_kg'].max():.3f} kg\")\n",
    "        \n",
    "        # Display first few results\n",
    "        print(\"\\nFirst 10 predictions:\")\n",
    "        display(results.head(10))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Batch inference failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Example data directories not found. Update the paths above to your actual data.\")\n",
    "    print(f\"Looking for RGB dir: {rgb_directory}\")\n",
    "    print(f\"Looking for Depth dir: {depth_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "Create visualizations of the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run if we have results from batch inference\n",
    "if 'results' in locals() and len(results) > 0:\n",
    "    # Plot histogram of predicted weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(results['predicted_weight_kg'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Predicted Weight (kg)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Predicted Weights')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot time series if we can extract timestamps\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(len(results)), results['predicted_weight_kg'], 'o-', alpha=0.7)\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Predicted Weight (kg)')\n",
    "    plt.title('Predicted Weights by Sample')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\nSummary Statistics:\")\n",
    "    print(results['predicted_weight_kg'].describe())\n",
    "    \n",
    "else:\n",
    "    print(\"No results available for visualization. Run batch inference first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Analysis\n",
    "\n",
    "Examine the features extracted from a sample image pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from a sample to understand the feature vector\n",
    "if os.path.exists(rgb_image_path) and os.path.exists(depth_file_path):\n",
    "    from pipeline.data_loader import ImagePairDataLoader\n",
    "    \n",
    "    # Load and preprocess the image pair\n",
    "    data_loader = ImagePairDataLoader(os.path.dirname(rgb_image_path), \n",
    "                                     os.path.dirname(depth_file_path), \n",
    "                                     config)\n",
    "    \n",
    "    rgb_image = data_loader.load_rgb_image(rgb_image_path)\n",
    "    depth_data = data_loader.load_depth_data(depth_file_path)\n",
    "    \n",
    "    # Extract individual feature types\n",
    "    features_2d = pipeline.extractor_2d.extract(rgb_image, rgb_image_path)\n",
    "    features_3d = pipeline.extractor_3d.extract(depth_data, depth_file_path)\n",
    "    features_resnet = pipeline.extractor_resnet.extract(rgb_image)\n",
    "    \n",
    "    print(\"Feature Analysis:\")\n",
    "    print(f\"2D Features ({len(features_2d)}):\")\n",
    "    for name, value in features_2d.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\n3D Features ({len(features_3d)}):\")\n",
    "    for name, value in features_3d.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "    \n",
    "    print(f\"\\nResNet Features: {features_resnet.shape[0]} dimensions\")\n",
    "    print(f\"ResNet feature stats - Mean: {np.mean(features_resnet):.4f}, Std: {np.std(features_resnet):.4f}\")\n",
    "    \n",
    "    # Show feature dimensions\n",
    "    feature_dims = pipeline.feature_fusion.get_feature_dimensions()\n",
    "    print(f\"\\nFeature Dimensions:\")\n",
    "    for feature_type, dim in feature_dims.items():\n",
    "        print(f\"  {feature_type}: {dim}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Sample data not available for feature analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison\n",
    "\n",
    "Compare predictions from different models if multiple are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models if available\n",
    "if pipeline.is_trained and os.path.exists(rgb_image_path) and os.path.exists(depth_file_path):\n",
    "    model_info = pipeline.get_model_info()\n",
    "    available_models = [m.replace('_model', '') for m in model_info.get('available_models', [])]\n",
    "    \n",
    "    if len(available_models) > 1:\n",
    "        print(\"Comparing model predictions:\")\n",
    "        \n",
    "        predictions = {}\n",
    "        for model_type in available_models:\n",
    "            try:\n",
    "                pred = pipeline.predict_from_images(rgb_image_path, depth_file_path, model_type)\n",
    "                predictions[model_type] = pred\n",
    "                print(f\"  {model_type.upper()}: {pred:.3f} kg\")\n",
    "            except Exception as e:\n",
    "                print(f\"  {model_type.upper()}: Failed ({e})\")\n",
    "        \n",
    "        if len(predictions) > 1:\n",
    "            # Calculate differences\n",
    "            pred_values = list(predictions.values())\n",
    "            max_diff = max(pred_values) - min(pred_values)\n",
    "            print(f\"\\nMaximum difference: {max_diff:.3f} kg\")\n",
    "            print(f\"Mean prediction: {np.mean(pred_values):.3f} kg\")\n",
    "    else:\n",
    "        print(f\"Only one model available: {available_models[0] if available_models else 'None'}\")\n",
    "        \n",
    "else:\n",
    "    print(\"Model comparison not available (models not loaded or sample data missing).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Results\n",
    "\n",
    "Save prediction results to files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results if we have them\n",
    "if 'results' in locals() and len(results) > 0:\n",
    "    output_file = \"prediction_results.csv\"\n",
    "    results.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Also save summary statistics\n",
    "    summary_file = \"prediction_summary.txt\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"Broiler Weight Prediction Summary\\n\")\n",
    "        f.write(\"=\" * 35 + \"\\n\\n\")\n",
    "        f.write(f\"Total samples: {len(results)}\\n\")\n",
    "        f.write(f\"Mean weight: {results['predicted_weight_kg'].mean():.3f} kg\\n\")\n",
    "        f.write(f\"Median weight: {results['predicted_weight_kg'].median():.3f} kg\\n\")\n",
    "        f.write(f\"Min weight: {results['predicted_weight_kg'].min():.3f} kg\\n\")\n",
    "        f.write(f\"Max weight: {results['predicted_weight_kg'].max():.3f} kg\\n\")\n",
    "        f.write(f\"Std deviation: {results['predicted_weight_kg'].std():.3f} kg\\n\")\n",
    "        \n",
    "    print(f\"Summary saved to {summary_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No results to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading the broiler weight estimation pipeline\n",
    "2. Running inference on single and multiple image pairs\n",
    "3. Analyzing features and model outputs\n",
    "4. Visualizing and exporting results\n",
    "\n",
    "To use this pipeline with your own data:\n",
    "1. Update the file paths to point to your RGB and depth data\n",
    "2. Ensure models are trained using `python pipeline/train.py`\n",
    "3. Adjust configuration in `pipeline/config.yaml` as needed\n",
    "\n",
    "For more information, see the pipeline documentation and README files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
